{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOqruikSV/NeVZZ4JoQStYy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fqwzbt7-5wKb","executionInfo":{"status":"ok","timestamp":1700688084030,"user_tz":-240,"elapsed":3422,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}},"outputId":"f7c7b646-62e3-4028-82b1-c4c9349aaf5a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'Transformers-Collab'...\n","remote: Enumerating objects: 589, done.\u001b[K\n","remote: Counting objects: 100% (589/589), done.\u001b[K\n","remote: Compressing objects: 100% (497/497), done.\u001b[K\n","remote: Total 589 (delta 143), reused 513 (delta 67), pack-reused 0\u001b[K\n","Receiving objects: 100% (589/589), 24.79 MiB | 24.45 MiB/s, done.\n","Resolving deltas: 100% (143/143), done.\n"]}],"source":["!git clone https://github.com/aakashvardhan/Transformers-Collab.git"]},{"cell_type":"code","source":["%cd Transformers-Collab"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TMSdOI5-5-2H","executionInfo":{"status":"ok","timestamp":1700688084030,"user_tz":-240,"elapsed":5,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}},"outputId":"d36148e4-d197-49f7-8865-763dc1904894"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/Transformers-Collab\n"]}]},{"cell_type":"code","source":["!python main.py 'gpt'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HI97Wj0x5_Ve","executionInfo":{"status":"ok","timestamp":1700688653903,"user_tz":-240,"elapsed":569876,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}},"outputId":"55c5ceab-a866-4fd3-e01d-10a63877474b"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Installing torchinfo...\n","Collecting torchinfo\n","  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n","Installing collected packages: torchinfo\n","Successfully installed torchinfo-1.8.0\n","tokenizer_config.json: 100% 28.0/28.0 [00:00<00:00, 155kB/s]\n","config.json: 100% 570/570 [00:00<00:00, 3.84MB/s]\n","vocab.txt: 100% 232k/232k [00:00<00:00, 3.52MB/s]\n","tokenizer.json: 100% 466k/466k [00:00<00:00, 3.45MB/s]\n","Token indices sequence length is longer than the specified maximum sequence length for this model (37443 > 512). Running this sequence through the model will result in indexing errors\n","Model with 89.48M parameters\n","step          0 | train loss 10.7336 | val loss 10.7361\n","step        100 | train loss 3.2966 | val loss 6.2213\n","step        200 | train loss 1.5818 | val loss 7.1870\n","step        300 | train loss 0.3727 | val loss 8.5639\n","step        400 | train loss 0.1709 | val loss 9.4483\n","step        499 | train loss 0.1372 | val loss 9.9500\n","Could not save model to checkpoints/checkpoint_epoch-499_22/11/2023_21:30:46.pt\n","Parent directory checkpoints/checkpoint_epoch-499_22/11 does not exist.\n","2023-11-22 21:30:48.840668: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-11-22 21:30:48.840725: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-11-22 21:30:48.840769: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-11-22 21:30:50.285193: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","[PAD] how did you evaluate your results must mention what loss function you picked and why! training must happen on the dataset except for boundary patching two inputs as well : well - in the input dataset except, you are making 3 versions of your 4th assignment, : you are looking at once in a proper readme describing all the your main. submit colab link to the readme. md file ( my notes ) studio video google meet version session 10 - backpropagation & architectural basics we\n"]}]}]}