{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMh0TF2vf8tG+UMu0DkOy3I"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wPkv9sX12jB_","executionInfo":{"status":"ok","timestamp":1700687522618,"user_tz":-240,"elapsed":2463,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}},"outputId":"97d16b16-2d47-4875-da57-d613846b8afb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'Transformers-Collab'...\n","remote: Enumerating objects: 577, done.\u001b[K\n","remote: Counting objects: 100% (577/577), done.\u001b[K\n","remote: Compressing objects: 100% (489/489), done.\u001b[K\n","remote: Total 577 (delta 136), reused 504 (delta 63), pack-reused 0\u001b[K\n","Receiving objects: 100% (577/577), 24.78 MiB | 32.33 MiB/s, done.\n","Resolving deltas: 100% (136/136), done.\n"]}],"source":["!git clone https://github.com/aakashvardhan/Transformers-Collab.git"]},{"cell_type":"code","source":["%cd Transformers-Collab"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sc4utFtF3Ilk","executionInfo":{"status":"ok","timestamp":1700687523205,"user_tz":-240,"elapsed":588,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}},"outputId":"dd05ff27-ff44-4c89-ee82-c565c7976ce2"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/Transformers-Collab\n"]}]},{"cell_type":"code","source":["!python main.py 'bert'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_kPP1b9v3NdR","executionInfo":{"status":"ok","timestamp":1700687584254,"user_tz":-240,"elapsed":61055,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}},"outputId":"4a82f616-f0f6-452b-baa1-64a638956eef"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Installing torchinfo...\n","Collecting torchinfo\n","  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n","Installing collected packages: torchinfo\n","Successfully installed torchinfo-1.8.0\n","loading text...\n","tokenizing sentences...\n","creating/loading vocab...\n","creating dataset...\n","initializing optimizer and loss...\n","training...\n","it: 0  | loss 10.32  | Δw: 1.417\n","it: 10  | loss 9.59  | Δw: 0.603\n","it: 20  | loss 9.36  | Δw: 0.416\n","it: 30  | loss 9.19  | Δw: 0.322\n","it: 40  | loss 9.01  | Δw: 0.269\n","it: 50  | loss 8.88  | Δw: 0.25\n","it: 60  | loss 8.73  | Δw: 0.244\n","it: 70  | loss 8.6  | Δw: 0.221\n","it: 80  | loss 8.36  | Δw: 0.204\n","it: 90  | loss 8.24  | Δw: 0.194\n","Traceback (most recent call last):\n","  File \"/content/Transformers-Collab/utils.py\", line 50, in save_model\n","    assert model_name.endswith(\".pth\") or model_name.endswith(\".pt\"), \"model_name should end with '.pt' or '.pth'\"\n","AssertionError: model_name should end with '.pt' or '.pth'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/content/Transformers-Collab/main.py\", line 39, in <module>\n","    train_bert(model, dataset, data_loader, vocab, config)\n","  File \"/content/Transformers-Collab/train.py\", line 76, in train_bert\n","    save_model(model=model, model_name=\"bert\", target_dir=\"saved_models\")\n","  File \"/content/Transformers-Collab/utils.py\", line 58, in save_model\n","    print(f\"Could not save model to {model_save_path}\")\n","UnboundLocalError: local variable 'model_save_path' referenced before assignment\n"]}]}]}